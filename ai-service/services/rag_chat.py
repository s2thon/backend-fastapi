# RAG pipeline (chatbot)

import os

from dotenv import load_dotenv
import google.generativeai as genai
from google.generativeai.types import GenerationConfig, Tool
from google.generativeai.protos import Part

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
from services.supabase_client import get_stock_info, get_price_info



# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# Gemini API yapÄ±landÄ±rmasÄ±
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
llm = genai.GenerativeModel("gemini-1.5-flash")

# Embedding nesnesi
embedding = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key=os.getenv("GEMINI_API_KEY")
)




# DÃ¶kÃ¼manlardan vektÃ¶r veritabanÄ± oluÅŸtur (tek seferlik)
def build_vector_store():
    file_paths = [
        "data/documents/faq.txt",
        "data/documents/policy.txt",
    ]

    docs = []
    for path in file_paths:
        loader = TextLoader(path, encoding="utf-8")
        docs.extend(loader.load())

    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(docs)

    vectorstore = FAISS.from_documents(chunks, embedding)
    vectorstore.save_local("../ai-service/embeddings/vector_store")

# VektÃ¶r veritabanÄ±nÄ± yÃ¼kle (eÄŸer yoksa oluÅŸtur)
if not os.path.exists("../ai-service/embeddings/vector_store/index.faiss"):
    build_vector_store()

db = FAISS.load_local("../ai-service/embeddings/vector_store", embedding, allow_dangerous_deserialization=True)


tools = [
    Tool(
        function_declarations=[
            {
                "name": "get_stock_info",
                "description": "Bir Ã¼rÃ¼nÃ¼n stokta kaÃ§ adet olduÄŸunu Ã¶ÄŸrenmek iÃ§in kullanÄ±lÄ±r. ÃœrÃ¼nÃ¼n adÄ±nÄ± parametre olarak alÄ±r.",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "product_name": {
                            "type": "STRING",
                            "description": "Stok bilgisi sorgulanacak Ã¼rÃ¼nÃ¼n adÄ± (Ã¶rn: 'KÄ±rmÄ±zÄ± Spor AyakkabÄ±')"
                        }
                    },
                    "required": ["product_name"]
                }
            },
            {
                "name": "get_price_info",
                "description": "Bir Ã¼rÃ¼nÃ¼n fiyatÄ±nÄ± Ã¶ÄŸrenmek iÃ§in kullanÄ±lÄ±r. KullanÄ±cÄ± 'fiyatÄ± ne kadar', 'kaÃ§ para', 'ne gadar' gibi ifadelerle veya yazÄ±m hatalarÄ±yla sorsa bile bu fonksiyonu kullan. ÃœrÃ¼nÃ¼n adÄ±nÄ± parametre olarak alÄ±r.",
                "parameters": {
                    "type": "OBJECT",
                    "properties": {
                        "product_name": {
                            "type": "STRING",
                            "description": "Fiyat bilgisi sorgulanacak Ã¼rÃ¼nÃ¼n adÄ± (Ã¶rn: 'Mavi GÃ¶mlek')"
                        }
                    },
                    "required": ["product_name"]
                }
            }
        ]
    )
]


system_instruction = """
### KÄ°MLÄ°K VE GÃ–REV TANIMI ###
Sen, bir e-ticaret platformunun yardÄ±msever ve profesyonel mÃ¼ÅŸteri hizmetleri asistanÄ±sÄ±n. Senin tek gÃ¶revin, kullanÄ±cÄ±lardan gelen sorularÄ± doÄŸru bir ÅŸekilde yanÄ±tlamaktÄ±r.

### DAVRANIÅ KURALLARI ###
1. PROFESYONEL DÄ°L KULLANIMI: CevaplarÄ±n daima resmi, net, kibar ve kurumsal bir dilde olmalÄ±dÄ±r. KullanÄ±cÄ±nÄ±n kullandÄ±ÄŸÄ± dil ne olursa olsun, sen bu profesyonel kimliÄŸinden asla Ã¶dÃ¼n verme.

2. GÄ°RDÄ°YÄ° ANLAMA, TAKLÄ°T ETMEME: KullanÄ±cÄ±lar argo, ÅŸive, yazÄ±m hatalarÄ± veya gÃ¼nlÃ¼k konuÅŸma dili kullanabilirler. Bu tÃ¼r ifadeleri anlamak senin gÃ¶revin, ancak cevaplarÄ±nda bunlarÄ± KESÄ°NLÄ°KLE KULLANMAMALISIN. Ã–rneÄŸin, "abi", "kardeÅŸim", "he gardaÅŸ", "eyvallah" gibi ifadeler kullanma.

3. ARAÃ‡ KULLANIMI Ã–NCELÄ°ÄÄ°: KullanÄ±cÄ±dan gelen soru, Ã¼rÃ¼nÃ¼n stok durumu, fiyatÄ±, mevcudiyeti veya buna benzer veritabanÄ± bilgilerini iÃ§eriyorsa, bu bilgileri tahmin etmeye Ã§alÄ±ÅŸmamalÄ±sÄ±n. Sana verilen ilgili fonksiyonlarÄ± (Ã¶rneÄŸin get_price_info, get_stock_info) kullanarak cevap vermelisin. Fonksiyonlar kullanÄ±lmadan yapÄ±lan cevaplar yanlÄ±ÅŸ olur.

4. ZORUNLU FONKSÄ°YON KULLANIMI: EÄŸer kullanÄ±cÄ± bir Ã¼rÃ¼nÃ¼n fiyatÄ±, Ã¼creti, tutarÄ±, maliyeti, bedeli veya stok durumu, adet bilgisi, elde olup olmadÄ±ÄŸÄ± gibi bilgileri soruyorsa, bu sorularÄ± belgelerden (faq.txt, policy.txt) cevaplamamalÄ±sÄ±n. Bu tÃ¼r bilgiler yalnÄ±zca ilgili fonksiyonlar Ã¼zerinden alÄ±nmalÄ±dÄ±r. RAG (belge arama) bu tÃ¼r sorular iÃ§in kullanÄ±lmamalÄ±dÄ±r.

### Ã–RNEK SENARYOLAR ###

- KULLANICI GÄ°RDÄ°SÄ°: "slm bu kÄ±rmÄ±zÄ± ayakkabÄ±dan elinizde var mÄ±?"
- DÃœÅÃœNCE SÃœRECÄ°N: KullanÄ±cÄ± bir Ã¼rÃ¼nÃ¼n stok durumunu soruyor. 'KÄ±rmÄ±zÄ± AyakkabÄ±' Ã¼rÃ¼n adÄ±dÄ±r. get_stock_info fonksiyonunu Ã§aÄŸÄ±rmalÄ±yÄ±m.
- Ã‡AÄRILACAK FONKSÄ°YON: get_stock_info(product_name='KÄ±rmÄ±zÄ± AyakkabÄ±')

- KULLANICI GÄ°RDÄ°SÄ°: "he gardas bu ipone 14 puro nun fiyatÄ± ne gadardÄ±r"
- DÃœÅÃœNCE SÃœRECÄ°N: KullanÄ±cÄ± yazÄ±m hatalarÄ±yla bir Ã¼rÃ¼nÃ¼n fiyatÄ±nÄ± soruyor. ÃœrÃ¼n 'iPhone 14 Pro' gibi duruyor. get_price_info fonksiyonunu Ã§aÄŸÄ±rmalÄ±yÄ±m.
- Ã‡AÄRILACAK FONKSÄ°YON: get_price_info(product_name='iPhone 14 Pro')

- KULLANICI GÄ°RDÄ°SÄ°: "iphone 14 pro'nun fiyatÄ± ne kadar?"
- DÃœÅÃœNCE SÃœRECÄ°N: KullanÄ±cÄ± doÄŸrudan fiyat soruyor. Belgelerden cevap vermemeliyim. Fonksiyonu kullanmalÄ±yÄ±m.
- Ã‡AÄRILACAK FONKSÄ°YON: get_price_info(product_name='iPhone 14 Pro')

- KULLANICI GÄ°RDÄ°SÄ°: "iade politikasÄ± hakkÄ±nda bilgi alabilir miyim"
- DÃœÅÃœNCE SÃœRECÄ°N: KullanÄ±cÄ± genel bir politika sorusu soruyor. Bu durumda belgelerden (RAG) cevap verebilirim. Fonksiyon gerekmez.
- Ã‡AÄRILACAK FONKSÄ°YON: Yok.

- KULLANICI GÄ°RDÄ°SÄ°: "bir Ã¼rÃ¼nÃ¼n fiyatÄ±nÄ± Ã¶ÄŸrenebilir miyim"
- DÃœÅÃœNCE SÃœRECÄ°N: KullanÄ±cÄ± fiyat sormuÅŸ ama Ã¼rÃ¼n adÄ± eksik. get_price_info fonksiyonunu Ã§aÄŸÄ±rmalÄ± ama Ã¼rÃ¼n adÄ± alÄ±nmalÄ±.
- YAPILACAK: ÃœrÃ¼n adÄ±nÄ± LLM ile belirle, sonra fonksiyonu Ã§aÄŸÄ±r.

### GENEL KURALLAR ###
- KullanÄ±cÄ±nÄ±n sorusunu dikkatle analiz et.
- KullanÄ±cÄ±nÄ±n dili gÃ¼nlÃ¼k de olsa, sen daima kurumsal ve netÂ cevapÂ ver.

"""



# Modeli, hem araÃ§larÄ± hem de YENÄ° sistem talimatÄ±nÄ± kullanacak ÅŸekilde yapÄ±landÄ±ralÄ±m
llm_with_tools = genai.GenerativeModel(
    "gemini-1.5-flash",
    tools=tools,
    system_instruction=system_instruction # <-- BURAYA EKLÄ°YORUZ
)

# Fonksiyon adlarÄ±nÄ± gerÃ§ek Python fonksiyonlarÄ±yla eÅŸleÅŸtiren bir harita
available_functions = {
    "get_stock_info": get_stock_info,
    "get_price_info": get_price_info,
}



def extract_product_name_with_llm(message: str) -> str:
    """
    KullanÄ±cÄ±nÄ±n mesajÄ±ndaki Ã¼rÃ¼n adÄ±nÄ± (marka + model) Ã§Ä±karmak iÃ§in LLM'e kÄ±sa bir prompt gÃ¶nderir.
    Geriye sadece Ã¼rÃ¼n adÄ± (Ã¶rneÄŸin: "iPhone 14 Pro") dÃ¶ner.
    """
    prompt = f"""
        AÅŸaÄŸÄ±daki kullanÄ±cÄ± mesajÄ±ndan sadece Ã¼rÃ¼nÃ¼n marka ve model adÄ±nÄ± Ã§Ä±kar. 
        CevabÄ±n sadece Ã¼rÃ¼n adÄ± olsun. BaÅŸka hiÃ§bir ÅŸey yazma. Nokta bile koyma.

        Mesaj: "{message}"

        ÃœrÃ¼n AdÄ±:
    """

    try:
        response = llm.generate_content(prompt)
        product_name = response.text.strip()
        
        # Temizlik: EÄŸer Ã¼rÃ¼n adÄ± tÄ±rnakla gelirse Ã§Ä±kar
        if product_name.startswith('"') and product_name.endswith('"'):
            product_name = product_name[1:-1].strip()

        return product_name
    except Exception as e:
        print(f"[extract_product_name_with_llm] Hata: {str(e)}")
        return ""





# âœ… Ana RAG fonksiyonu
from google.generativeai.protos import Part

# ... (mevcut llm, tool, db, available_functions tanÄ±mlamalarÄ±) ...

# âœ… Ana RAG fonksiyonunun SON ve DOÄRU hali
def rag_chat(user_input: str) -> str:
    # Ã–n iÅŸleme â€“ KÃ¼Ã§Ã¼k harfe Ã§evir ve temizle
    lower_input = user_input.lower()

    # âœ… 1. ADIM â€“ Anahtar kelimeye gÃ¶re Ã¶n kontrol (fonksiyon zorlamasÄ±)
    if any(kw in lower_input for kw in ["fiyat", "kaÃ§ para", "ne kadar", "Ã¼cret", "tutar", "fiyati", "maliyeti"]):
        product_name = extract_product_name_with_llm(user_input)
        if not product_name:
            return "ÃœrÃ¼n adÄ±nÄ± anlayamadÄ±m. LÃ¼tfen daha net bir ÅŸekilde belirtir misiniz?"
        return get_price_info(product_name)

    if any(kw in lower_input for kw in ["stok", "var mÄ±", "kaldÄ± mÄ±", "mevcut", "adet", "stokta", "elde"]):
        product_name = extract_product_name_with_llm(user_input)
        if not product_name:
            return "Stok bilgisi iÃ§in Ã¼rÃ¼n adÄ±nÄ± net olarak belirtmeniz gerekiyor."
        return get_stock_info(product_name)

    # âœ… 2. ADIM â€“ Normal LLM & tool-based akÄ±ÅŸ (genel sorular iÃ§in)
    chat = llm_with_tools.start_chat()
    response = chat.send_message(user_input)
    response_part = response.parts[0]

    # âœ… 3. ADIM â€“ LLM fonksiyon Ã§aÄŸÄ±rmak isterse
    if response_part.function_call.name:
        function_call = response_part.function_call
        function_name = function_call.name
        function_args = function_call.args

        if function_name in available_functions:
            print(f"ğŸ§  LLM fonksiyon Ã§aÄŸÄ±rÄ±yor: {function_name} â†’ {dict(function_args)}")

            function_to_call = available_functions[function_name]
            result = function_to_call(product_name=function_args["product_name"])

            final_response = chat.send_message(
                Part(function_response={
                    "name": function_name,
                    "response": {"result": result}
                })
            )
            return final_response.text.strip()
        else:
            return f"Hata: TanÄ±nmayan fonksiyon: {function_name}"

    # âœ… 4. ADIM â€“ Fonksiyon Ã§aÄŸrÄ±sÄ± yoksa RAG'e baÅŸvur
    print("ğŸ§  Fonksiyon Ã§aÄŸrÄ±sÄ± yapÄ±lmadÄ±, RAG (belge aramasÄ±) Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
    docs = db.similarity_search(user_input, k=3)
    context = "\n\n".join(doc.page_content for doc in docs)

    prompt = f"""
    AÅŸaÄŸÄ±daki bilgiler, kullanÄ±cÄ±nÄ±n sorusuna yardÄ±mcÄ± olabilir. EÄŸer bilgi yetersizse, uydurma yapma.
    Bilgi:\n{context}\n
    Soru: {user_input}
    Cevap:
    """

    try:
        response = llm.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"[AI HatasÄ±]:Â {str(e)}"
# Embedding dosyasÄ±nÄ± baÅŸlatmak iÃ§in
if __name__ == "__main__":
    build_vector_store()
    print("âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu.")
