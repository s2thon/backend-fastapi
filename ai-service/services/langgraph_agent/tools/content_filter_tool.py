from langchain_core.tools import tool

@tool  
def content_filter_tool(text: str) -> str:
    """
    Metin iÃ§eriÄŸini analiz eder ve uygunluk seviyesini deÄŸerlendirir.
    """
    # ... (fonksiyonun geri kalanÄ± aynÄ±, deÄŸiÅŸiklik yok) ...
    print(f"ğŸ›¡ï¸ Ä°Ã§erik Filtre AracÄ± Ã‡aÄŸrÄ±ldÄ±.")
    score = 100
    issues = []
    profanity_words = ["aptl", "sktir", "amk", "mk"]
    found_profanity = [word for word in profanity_words if word in text.lower()]
    if found_profanity:
        score -= 30
        issues.append(f"Uygunsuz dil tespit edildi: {', '.join(found_profanity)}")
    aggressive_indicators = ["zorla", "hemen", "acil", "!!!", "???"]
    found_aggressive = [indicator for indicator in aggressive_indicators if indicator in text.lower()]
    if found_aggressive:
        score -= 10
        issues.append("Agresif ton tespit edildi")
    if score >= 80:
        return "Ä°Ã‡ERÄ°K UYGUN: Metin analizi baÅŸarÄ±lÄ±."
    elif score >= 60:
        return f"Ä°Ã‡ERÄ°K ÅÃœPHELI: {', '.join(issues)}. Dikkatli yanÄ±t verilmeli."
    else:
        return f"Ä°Ã‡ERÄ°K UYGUNSUZ: {', '.join(issues)}. Ä°stek reddedilmelidir."